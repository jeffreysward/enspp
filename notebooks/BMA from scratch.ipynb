{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was written before I decided to go with the `ensembleBMA` route.  \n",
    "Refer to the data preprocessing steps in `BMA.ipynb` if you need to run the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stats.linregress(data['Lee 2017'], data['Obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['Lee 2017'], data['Obs'], 'o', label='original data')\n",
    "plt.plot(data['Lee 2017'], result.intercept + result.slope*data['Lee 2017'], 'r', label='fitted line')\n",
    "plt.legend()\n",
    "plt.xlabel('Forecast Wind Speed $ms^{-1}$')\n",
    "plt.ylabel('Observed Wind Speed $ms^{-1}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, linearity only seems to be a marginally good assumption here... perhaps we should replace this with some type of polynomial or maybe logistic regression? For the other parameters, we must carry out minimization of the log-likelihood function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortunately, we have no zero wind speed values, which means that we don't have to do the more complicated MLE method proposed by Wilkes in 1990\n",
    "(wrfens == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(obs == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the mean parameters from linear regression\n",
    "b0 = result.intercept \n",
    "b1 = result.slope\n",
    "fx = data.loc['2020-02-11 23:50', 'Lee 2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mu(fx, b0, b1):\n",
    "    '''\n",
    "    Estimate the mean, mu_k\n",
    "    '''\n",
    "    mu = b0 + b1 * fx\n",
    "    return mu\n",
    "\n",
    "    \n",
    "def get_sigma(fx, c0, c1):\n",
    "    '''\n",
    "    Estimate the standard deviation, sigma_k \n",
    "    '''\n",
    "    sigma = c0 + c1 * fx\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_probability(obs, mu, sigma, w):\n",
    "    '''\n",
    "    Get the weighted PDF for a single instance (i.e., one observation)\n",
    "    '''\n",
    "    alpha = mu**2 / sigma**2\n",
    "    beta = alpha / mu \n",
    "    weighted_pdf = w * stats.gamma.pdf(obs, alpha, loc = 0.0, scale = 1.0/beta)\n",
    "    return weighted_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log-liklihood calculation\n",
    "def get_log_lik(parameters):\n",
    "    # extract parameters\n",
    "    const, beta, std_dev = parameters\n",
    "    # predict the output\n",
    "    pred = const + beta*x\n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    log_lik = np.sum(stats.gamma.logpdf(y, pred, std_dev))\n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_log_lik = -1 * log_lik\n",
    "    return neg_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize arguments: function, intial_guess_of_parameters, method\n",
    "mle_model = opt.minimize(get_log_lik, np.array([2,2,2]), method='L-BFGS-B')\n",
    "mle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
