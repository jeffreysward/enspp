{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enspp.vis as vis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import STAP\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import stoc_solar\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from wrfpywind import data_preprocess as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file with the R code\n",
    "with open('../R/gamma_bma.r', 'r') as f:\n",
    "    string = f.read()\n",
    "\n",
    "# Parse the package using STAP\n",
    "gamma_bma = STAP(string, \"gamma_bma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the ensemble and observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrfens = pp.fmt_wrfens_wspd(wrfout_headdir='../data/', \n",
    "                    wrfout_dirs=['28mp4lw4sw2lsm5pbl1cu/',  # Lee 2017\n",
    "                                 '8mp1lw1sw2lsm1pbl1cu/',  # Draxl 2014a\n",
    "                                 '8mp1lw1sw2lsm2pbl1cu/',  # Draxl 2014b\n",
    "                                 '8mp1lw1sw2lsm2pbl3cu/',  # Vernon 2018\n",
    "                                 '8mp4lw2sw2lsm5pbl3cu/',  # Optis 2021\n",
    "                                 ],\n",
    "                    wrfout_files=['ow_buoy_wrfout_d03_2020-02-05-2020-02-11',\n",
    "                                #   'ow_buoy_wrfout_d03_2020-06-03-2020-06-09',\n",
    "                                #   'ow_buoy_wrfout_d03_2020-07-01-2020-07-07',\n",
    "                                #   'ow_buoy_wrfout_d03_2020-11-26-2020-12-02',\n",
    "                                  ],\n",
    "                    model_names=['Lee 2017', 'Draxl 2014a', 'Draxl 2014b', 'Veron 2018', 'Optis 2021'],\n",
    "                    heights=[20, 40, 60, 80, 100, 120, 140, 160, 180, 200],\n",
    "                    locations=['south', 'north']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pp.fmt_buoy_wspd(\n",
    "                       data_path='/Users/jeffreysward/Box Sync/01_Research/01_Renewable_Analysis/WRF_Solar_and_Wind/oshwind/wrfpywind/wrfpywind/data/nyserda_buoy/',\n",
    "                     #   data_path='/share/mzhang/jas983/wrf_data/oshwind/wrfpywind/wrfpywind/data/nyserda_buoy/', \n",
    "                       south_dates_str='20190904_20210207', north_dates_str='20190812_20210207', \n",
    "                       heights=[20, 40, 60, 80, 100, 120, 140, 160, 180, 200],\n",
    "                       start_date='01-01-2020', end_date='12-31-2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for only north buoy at 100m and format\n",
    "wrfens_n = wrfens.sel(location='north', height=100)\n",
    "wrfens_n = wrfens_n.T.to_pandas()\n",
    "obs_n = obs.sel(location='north', height=100)\n",
    "obs_n = obs_n.T.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the observations and the ensemble forecast into the same DataFrame (north buoy)\n",
    "data_n = pd.concat([obs_n['2020-02-05':'2020-02-11'], wrfens_n], axis=1)\n",
    "data_n = data_n.rename(columns={0: 'Obs'})\n",
    "data_n = data_n.dropna().reset_index()\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'location' in wrfens.dims:\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for only north buoy at 100m and format\n",
    "wrfens_n = wrfens.sel(location='north', height=100)\n",
    "obs_n = obs.sel(Time=slice(wrfens.Time[0], wrfens.Time[-1]), location='north', height=100)\n",
    "# Put the observations and the ensemble forecast into the same DataFrame (north buoy)\n",
    "data_n = xr.concat([obs_n, wrfens_n], 'model')\n",
    "data_n = data_n.T.to_pandas().dropna().reset_index()\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for only south buoy at 100m and format\n",
    "wrfens_s = wrfens.sel(location='south', height=100)\n",
    "wrfens_s = wrfens_s.T.to_pandas()\n",
    "obs_s = obs.sel(location='south', height=100)\n",
    "obs_s = obs_s.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the observations and the ensemble forecast into the same DataFrame (south buoy)\n",
    "data_s = pd.concat([obs_s['2020-02-05':'2020-02-11'], wrfens_s], axis=1)\n",
    "data_s = data_s.rename(columns={0: 'Obs'})\n",
    "data_s = data_s.dropna().reset_index()\n",
    "data_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data from the two buoys into the same dataframe \n",
    "data = pd.concat([data_s, data_n], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a BMA model\n",
    "We will estimate the BMA parameters using the R `ensembleBMA` package with the help of the `rpy2` Python package\n",
    "\n",
    "Since the Sloughter 2010 paper use the gamma distribution, I think I'll just proceed with the Gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data = data[data['Time'] < '2020-02-11'].reset_index(drop=True)\n",
    "test_data = data[data['Time'] >= '2020-02-11'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the BMA model \n",
    "fit = gamma_bma.fit_bma(train_data, n_ens_members=5)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that typing `print(fit)` into the notbook allows you to view the BMA fit, but that simply typing `fit` will draw an uninteligable error for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the quantiles for a set set of testing data. In this case, \n",
    "# we don't want to supply the full set of testing data as this includes both locations, \n",
    "# so we will first define a new set of testing data.\n",
    "test_n = data_n[data_n['Time'] >= '2020-02-11'].reset_index(drop=True)\n",
    "q = gamma_bma.quant_bma(fit, test_n, n_ens_members=5, quantiles=np.arange(0.01, 1, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the CRPS\n",
    "crps = gamma_bma.crps_bma(fit, test_data, n_ens_members = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine the optimal amount of training data, I will probably use the mean CRPS\n",
    "np.mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the forecast and observations using stoc_solar.fan\n",
    "stoc_solar.fan(fx=q.T, obs=test_n.Obs.values, p1=None, p2=None, t_issue='01/01/2018', fx_res='H', title=None, \n",
    "               percentile_vals=[ii + 1 for ii in range(0, 99)], fig_w=15,\n",
    "               ylab=True, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's nice that my `stoc_solar.fan` plot works okay here, I think I'm going to duplicate this function for `enspp` and customize it for wind speed -- hopefully this version will be more portable.  \n",
    "Also, this will require some formatting of the `fx` and `obs` input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the forecast and obs variables into xarray DataSets. Note the obnoxious bug, \n",
    "# which means that I had to write test_n.Time[0:1] rather than simply test_n.Time\n",
    "fx = xr.DataArray(\n",
    "    data=[q],\n",
    "    dims=[\n",
    "        \"Start_time\", \n",
    "        \"Step_index\", \n",
    "        \"Percentile\"\n",
    "        ],\n",
    "    coords=dict(\n",
    "        Start_time=test_n.Time[0:1],\n",
    "        Step_index=test_n.index,\n",
    "        Percentile=np.arange(1, 100, 1),\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"Wind Speed 100m\",\n",
    "        units=\"m s-1\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the observations, I can simply use the `obs` `xarray.DataSet` that I read in using `pp.fmt_buoy_wspd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_n_100 = obs.sel(location='north', height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.fan(fx=fx, obs=obs_n_100, p1=None, p2=None, t_issue='02/11/2020', n_days=1, fx_res='10T', title=None, \n",
    "    percentile_vals=None, fig_w=15, ylab=True, ylab_txt='Wind Speed (ms$^{-1}$)', \n",
    "    show_fig=True, save_fig=False, fig_path='../data/plots/fan_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Map of a Specific Quantile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the DataArray contianing wind speed data for the entire domain\n",
    "ensda = xr.open_dataarray('/share/mzhang/jas983/wrf_data/oshwind/wrfpywind/wrfpywind/data/ensds_20200204-12.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data for the test day (2020-02-11) at 100m\n",
    "ensda = ensda.sel(Time=slice('2020-02-11', ensda.Time[-2].values), height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for only one location\n",
    "ensda_slice = ensda.isel(south_north=0, west_east=0)\n",
    "ensdf_slice = ensda_slice.T.to_pandas()\n",
    "ensdf_slice.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need an observation as a placeholder (it won't actually be used), so we'll use the one from the north buoy\n",
    "data_t = pd.concat([obs_n['2020-02-11'], ensdf_slice], axis=1)\n",
    "data_t = data_t.rename(columns={0: 'Obs'})\n",
    "data_t = data_t.reset_index()\n",
    "data_t.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the quantiles using the BMA test fit\n",
    "q = gamma_bma.quant_bma(fit, data_t, n_ens_members=5, quantiles=np.arange(0.01, 1, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the quantiles into a DataArray\n",
    "fx = fxda(q, ensda_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxda(quantiles, ensda):    \n",
    "    # Format the forecast and obs variables into xarray DataSets. \n",
    "    fx = xr.DataArray(\n",
    "        data=[quantiles],\n",
    "        dims=[\n",
    "            \"Start_time\", \n",
    "            \"Step_index\", \n",
    "            \"Percentile\"\n",
    "            ],\n",
    "        coords=dict(\n",
    "            Start_time=ensda.Time[0:1].values,\n",
    "            Step_index=np.arange(0, len(ensda_slice.Time), 1),\n",
    "            Percentile=np.arange(1, q.shape[1] + 1, 1),\n",
    "            XLONG=ensda_slice.XLONG.values,\n",
    "            XLAT=ensda_slice.XLAT.values\n",
    "        ),\n",
    "        attrs=dict(\n",
    "            description=\"Wind Speed 100m\",\n",
    "            units=\"m s-1\",\n",
    "        ),\n",
    "    )\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is currently quite slow...\n",
    "# Loop over the south_north dimension\n",
    "# for ii in range(0, len(ensda.XLAT)):\n",
    "for ii in range(0, 2):\n",
    "    # Loop over the west_east dimension\n",
    "    # for jj in range(0, len(ensda.XLONG)):\n",
    "    for jj in range(0, 2):\n",
    "        # Select data for only one location\n",
    "        ensda_slice = ensda.isel(south_north=ii, west_east=jj)\n",
    "        ensdf_slice = ensda_slice.T.to_pandas()\n",
    "        # We need an observation as a placeholder (it won't actually be used), \n",
    "        # so we'll use the one from the north buoy\n",
    "        data_t = pd.concat([obs_n['2020-02-11'], ensdf_slice], axis=1)\n",
    "        data_t = data_t.rename(columns={0: 'Obs'})\n",
    "        data_t = data_t.reset_index()\n",
    "        # Extract the quantiles using the BMA test fit\n",
    "        q = gamma_bma.quant_bma(fit, data_t, n_ens_members=5, quantiles=np.arange(0.01, 1, 0.01))\n",
    "        # Format the quantiles into a DataArray\n",
    "        fx_we_new = fxda(q, ensda_slice)\n",
    "        # Combine the DataArrays over the west_east dimension\n",
    "        if jj == 0:\n",
    "            fx_we = fx_we_new\n",
    "        else:\n",
    "            fx_we = xr.concat([fx_we, fx_we_new], 'west_east')\n",
    "    # Combine DataArrays over the south_north dimension\n",
    "    if ii == 0:\n",
    "        fx = fx_we\n",
    "    else:\n",
    "        fx = xr.concat([fx, fx_we], 'south_north')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "419e07bb6a6cac3dbe3070add9cab248ac326587879038172cc7438d8f9ffe8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('oshwind': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
